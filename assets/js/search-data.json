{
  
    
        "post0": {
            "title": "Extracting features from text files",
            "content": "Table of Contents . Data Set | Defining a Baseline Model | Introduction to Deep Neural Networks Introducing Keras API | First Keras Model | . | What Is a Word Embedding? One-Hot Encoding | Word Embeddings | Keras Embedding Layer | . | Convolutional Neural Networks (CNN) | Hyperparameters Optimization | . Importing Packages . import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import matplotlib.pyplot as plt from sklearn.feature_extraction.text import CountVectorizer from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import OneHotEncoder from sklearn.model_selection import RandomizedSearchCV import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras import layers from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.wrappers.scikit_learn import KerasClassifier import os print(os.listdir(&quot;../input&quot;)) plt.style.use(&#39;ggplot&#39;) . [&#39;sentiment labelled sentences&#39;] . Extract the folder into a data folder and go ahead and load the data with Pandas: . filepath_dict = {&#39;yelp&#39;: &#39;../input/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt&#39;, &#39;amazon&#39;: &#39;../input/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt&#39;, &#39;imdb&#39;: &#39;../input/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt&#39;} df_list = [] for source, filepath in filepath_dict.items(): df = pd.read_csv(filepath, names=[&#39;sentence&#39;, &#39;label&#39;], sep=&#39; t&#39;) df[&#39;source&#39;] = source df_list.append(df) . len(df_list) . 3 . df_list . [ sentence label source 0 Wow... Loved this place. 1 yelp 1 Crust is not good. 0 yelp 2 Not tasty and the texture was just nasty. 0 yelp 3 Stopped by during the late May bank holiday of... 1 yelp 4 The selection on the menu was great and so wer... 1 yelp 5 Now I am getting angry and I want my damn pho. 0 yelp 6 Honeslty it didn&#39;t taste THAT fresh.) 0 yelp 7 The potatoes were like rubber and you could te... 0 yelp 8 The fries were great too. 1 yelp 9 A great touch. 1 yelp 10 Service was very prompt. 1 yelp 11 Would not go back. 0 yelp 12 The cashier had no care what so ever on what I... 0 yelp 13 I tried the Cape Cod ravoli, chicken,with cran... 1 yelp 14 I was disgusted because I was pretty sure that... 0 yelp 15 I was shocked because no signs indicate cash o... 0 yelp 16 Highly recommended. 1 yelp 17 Waitress was a little slow in service. 0 yelp 18 This place is not worth your time, let alone V... 0 yelp 19 did not like at all. 0 yelp 20 The Burrittos Blah! 0 yelp 21 The food, amazing. 1 yelp 22 Service is also cute. 1 yelp 23 I could care less... The interior is just beau... 1 yelp 24 So they performed. 1 yelp 25 That&#39;s right....the red velvet cake.....ohhh t... 1 yelp 26 - They never brought a salad we asked for. 0 yelp 27 This hole in the wall has great Mexican street... 1 yelp 28 Took an hour to get our food only 4 tables in ... 0 yelp 29 The worst was the salmon sashimi. 0 yelp .. ... ... ... 970 I immediately said I wanted to talk to the man... 0 yelp 971 The ambiance isn&#39;t much better. 0 yelp 972 Unfortunately, it only set us up for disapppoi... 0 yelp 973 The food wasn&#39;t good. 0 yelp 974 Your servers suck, wait, correction, our serve... 0 yelp 975 What happened next was pretty....off putting. 0 yelp 976 too bad cause I know it&#39;s family owned, I real... 0 yelp 977 Overpriced for what you are getting. 0 yelp 978 I vomited in the bathroom mid lunch. 0 yelp 979 I kept looking at the time and it had soon bec... 0 yelp 980 I have been to very few places to eat that und... 0 yelp 981 We started with the tuna sashimi which was bro... 0 yelp 982 Food was below average. 0 yelp 983 It sure does beat the nachos at the movies but... 0 yelp 984 All in all, Ha Long Bay was a bit of a flop. 0 yelp 985 The problem I have is that they charge $11.99 ... 0 yelp 986 Shrimp- When I unwrapped it (I live only 1/2 a... 0 yelp 987 It lacked flavor, seemed undercooked, and dry. 0 yelp 988 It really is impressive that the place hasn&#39;t ... 0 yelp 989 I would avoid this place if you are staying in... 0 yelp 990 The refried beans that came with my meal were ... 0 yelp 991 Spend your money and time some place else. 0 yelp 992 A lady at the table next to us found a live gr... 0 yelp 993 the presentation of the food was awful. 0 yelp 994 I can&#39;t tell you how disappointed I was. 0 yelp 995 I think food should have flavor and texture an... 0 yelp 996 Appetite instantly gone. 0 yelp 997 Overall I was not impressed and would not go b... 0 yelp 998 The whole experience was underwhelming, and I ... 0 yelp 999 Then, as if I hadn&#39;t wasted enough of my life ... 0 yelp [1000 rows x 3 columns], sentence label source 0 So there is no way for me to plug it in here i... 0 amazon 1 Good case, Excellent value. 1 amazon 2 Great for the jawbone. 1 amazon 3 Tied to charger for conversations lasting more... 0 amazon 4 The mic is great. 1 amazon 5 I have to jiggle the plug to get it to line up... 0 amazon 6 If you have several dozen or several hundred c... 0 amazon 7 If you are Razr owner...you must have this! 1 amazon 8 Needless to say, I wasted my money. 0 amazon 9 What a waste of money and time!. 0 amazon 10 And the sound quality is great. 1 amazon 11 He was very impressed when going from the orig... 1 amazon 12 If the two were seperated by a mere 5+ ft I st... 0 amazon 13 Very good quality though 1 amazon 14 The design is very odd, as the ear &#34;clip&#34; is n... 0 amazon 15 Highly recommend for any one who has a blue to... 1 amazon 16 I advise EVERYONE DO NOT BE FOOLED! 0 amazon 17 So Far So Good!. 1 amazon 18 Works great!. 1 amazon 19 It clicks into place in a way that makes you w... 0 amazon 20 I went on Motorola&#39;s website and followed all ... 0 amazon 21 I bought this to use with my Kindle Fire and a... 1 amazon 22 The commercials are the most misleading. 0 amazon 23 I have yet to run this new battery below two b... 1 amazon 24 I bought it for my mother and she had a proble... 0 amazon 25 Great Pocket PC / phone combination. 1 amazon 26 I&#39;ve owned this phone for 7 months now and can... 1 amazon 27 I didn&#39;t think that the instructions provided ... 0 amazon 28 People couldnt hear me talk and I had to pull ... 0 amazon 29 Doesn&#39;t hold charge. 0 amazon .. ... ... ... 970 I plugged it in only to find out not a darn th... 0 amazon 971 Excellent product. 1 amazon 972 Earbud piece breaks easily. 0 amazon 973 Lousy product. 0 amazon 974 This phone tries very hard to do everything bu... 0 amazon 975 It is the best charger I have seen on the mark... 1 amazon 976 SWEETEST PHONE!!! 1 amazon 977 :-)Oh, the charger seems to work fine. 1 amazon 978 It fits so securely that the ear hook does not... 1 amazon 979 Not enough volume. 0 amazon 980 Echo Problem....Very unsatisfactory 0 amazon 981 you could only take 2 videos at a time and the... 0 amazon 982 don&#39;t waste your money. 0 amazon 983 I am going to have to be the first to negative... 0 amazon 984 Adapter does not provide enough charging current. 0 amazon 985 There was so much hype over this phone that I ... 0 amazon 986 You also cannot take pictures with it in the c... 0 amazon 987 Phone falls out easily. 0 amazon 988 It didn&#39;t work, people can not hear me when I ... 0 amazon 989 The text messaging feature is really tricky to... 0 amazon 990 I&#39;m really disappointed all I have now is a ch... 0 amazon 991 Painful on the ear. 0 amazon 992 Lasted one day and then blew up. 0 amazon 993 disappointed. 0 amazon 994 Kind of flops around. 0 amazon 995 The screen does get smudged easily because it ... 0 amazon 996 What a piece of junk.. I lose more calls on th... 0 amazon 997 Item Does Not Match Picture. 0 amazon 998 The only thing that disappoint me is the infra... 0 amazon 999 You can not answer calls with the unit, never ... 0 amazon [1000 rows x 3 columns], sentence label source 0 A very, very, very slow-moving, aimless movie ... 0 imdb 1 Not sure who was more lost - the flat characte... 0 imdb 2 Attempting artiness with black &amp; white and cle... 0 imdb 3 Very little music or anything to speak of. 0 imdb 4 The best scene in the movie was when Gerardo i... 1 imdb 5 The rest of the movie lacks art, charm, meanin... 0 imdb 6 Wasted two hours. 0 imdb 7 Saw the movie today and thought it was a good ... 1 imdb 8 A bit predictable. 0 imdb 9 Loved the casting of Jimmy Buffet as the scien... 1 imdb 10 And those baby owls were adorable. 1 imdb 11 The movie showed a lot of Florida at it&#39;s best... 1 imdb 12 The Songs Were The Best And The Muppets Were S... 1 imdb 13 It Was So Cool. 1 imdb 14 This is a very &#34;right on case&#34; movie that deli... 1 imdb 15 It had some average acting from the main perso... 0 imdb 16 This review is long overdue, since I consider ... 1 imdb 17 I&#39;ll put this gem up against any movie in term... 1 imdb 18 It&#39;s practically perfect in all of them  a tr... 1 imdb 19 The structure of this film is easily the most... 0 imdb 20 This if the first movie I&#39;ve given a 10 to in ... 1 imdb 21 If there was ever a movie that needed word-of-... 1 imdb 22 Overall, the film is interesting and thought-p... 1 imdb 23 Plus, it was well-paced and suited its relativ... 1 imdb 24 Give this one a look. 1 imdb 25 I gave it a 10 1 imdb 26 The Wind and the Lion is well written and supe... 1 imdb 27 It is a true classic. 1 imdb 28 It actually turned out to be pretty decent as ... 1 imdb 29 Definitely worth checking out. 1 imdb .. ... ... ... 718 Enough can not be said of the remarkable anima... 1 imdb 719 The art style has the appearance of crayon/pen... 1 imdb 720 If you act in such a film, you should be glad ... 0 imdb 721 This one wants to surf on the small wave of sp... 0 imdb 722 If you haven&#39;t choked in your own vomit by the... 0 imdb 723 Still, it makes up for all of this with a supe... 1 imdb 724 Just consider the excellent story, solid actin... 1 imdb 725 Instead, we got a bore fest about a whiny, spo... 0 imdb 726 Then I watched it again two Sundays ago (March... 1 imdb 727 It is a very well acted and done TV Movie. 1 imdb 728 Judith Light is one of my favorite actresses a... 1 imdb 729 I keep watching it over and over. 1 imdb 730 It&#39;s a sad movie, but very good. 1 imdb 731 If you have not seen this movie, I definitely ... 1 imdb 732 She is as lovely as usual, this cutie! 1 imdb 733 Still it&#39;s quite interesting and entertaining ... 1 imdb 734 ;) Recommend with confidence! 1 imdb 735 This movie is well-balanced with comedy and dr... 1 imdb 736 It was a riot to see Hugo Weaving play a sex-o... 1 imdb 737 :) Anyway, the plot flowed smoothly and the ma... 1 imdb 738 The opening sequence of this gem is a classic,... 1 imdb 739 Fans of the genre will be in heaven. 1 imdb 740 Lange had become a great actress. 1 imdb 741 It looked like a wonderful story. 1 imdb 742 I never walked out of a movie faster. 0 imdb 743 I just got bored watching Jessice Lange take h... 0 imdb 744 Unfortunately, any virtue in this film&#39;s produ... 0 imdb 745 In a word, it is embarrassing. 0 imdb 746 Exceptionally bad! 0 imdb 747 All in all its an insult to one&#39;s intelligence... 0 imdb [748 rows x 3 columns]] . df = pd.concat(df_list) df.iloc[0] . sentence Wow... Loved this place. label 1 source yelp Name: 0, dtype: object . df.head() . sentence label source . 0 Wow... Loved this place. | 1 | yelp | . 1 Crust is not good. | 0 | yelp | . 2 Not tasty and the texture was just nasty. | 0 | yelp | . 3 Stopped by during the late May bank holiday of... | 1 | yelp | . 4 The selection on the menu was great and so wer... | 1 | yelp | . df.tail() . sentence label source . 743 I just got bored watching Jessice Lange take h... | 0 | imdb | . 744 Unfortunately, any virtue in this film&#39;s produ... | 0 | imdb | . 745 In a word, it is embarrassing. | 0 | imdb | . 746 Exceptionally bad! | 0 | imdb | . 747 All in all its an insult to one&#39;s intelligence... | 0 | imdb | . Now use the CountVectorizer provided by the scikit-learn library to vectorize sentences. It takes the words of each sentence and creates a vocabulary of all the unique words in the sentences. This vocabulary can then be used to create a feature vector of the count of the words: . sentences = [&#39;Rashmi likes ice cream&#39;, &#39;Rashmi hates chocolate.&#39;] . vectorizer = CountVectorizer(min_df=0, lowercase=False) vectorizer.fit(sentences) vectorizer.vocabulary_ . {&#39;Rashmi&#39;: 0, &#39;likes&#39;: 5, &#39;ice&#39;: 4, &#39;cream&#39;: 2, &#39;hates&#39;: 3, &#39;chocolate&#39;: 1} . vectorizer.vocabulary_.get(u&#39;ice&#39;) . 4 . d = vectorizer.vocabulary_ {key:d[key] for key in sorted(d.keys())} . {&#39;Rashmi&#39;: 0, &#39;chocolate&#39;: 1, &#39;cream&#39;: 2, &#39;hates&#39;: 3, &#39;ice&#39;: 4, &#39;likes&#39;: 5} . vocabulary_list=[[key for key in sorted(d.keys())],[d[key] for key in sorted(d.keys())]] . vocabulary_list . [[&#39;Rashmi&#39;, &#39;chocolate&#39;, &#39;cream&#39;, &#39;hates&#39;, &#39;ice&#39;, &#39;likes&#39;], [0, 1, 2, 3, 4, 5]] . vectorizer.transform(sentences).toarray() . array([[1, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0]]) . vectorizer.transform(sentences).toarray()[1] . array([1, 1, 0, 1, 0, 0]) . vectors = vectorizer.transform(sentences).toarray().tolist() vectors . [[1, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0]] . data = [vocabulary_list[0],vectors[0],vectors[1]] pd.DataFrame(data) . 0 1 2 3 4 5 . 0 Rashmi | chocolate | cream | hates | ice | likes | . 1 1 | 0 | 1 | 0 | 1 | 1 | . 2 1 | 1 | 0 | 1 | 0 | 0 | . Defining a Baseline Model . First, you are going to split the data into a training and testing set which will allow you to evaluate the accuracy and see if your model generalizes well. This means whether the model is able to perform well on data it has not seen before. This is a way to see if the model is overfitting. . Overfitting is when a model is trained too well on the training data. You want to avoid overfitting, as this would mean that the model mostly just memorized the training data. This would account for a large accuracy with the training data but a low accuracy in the testing data. . We start by taking the Yelp data set which we extract from our concatenated data set. From there, we take the sentences and labels. . df_yelp = df[df[&#39;source&#39;] == &#39;yelp&#39;] sentences = df_yelp[&#39;sentence&#39;].values y = df_yelp[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000) . Create the feature vectors for each sentence of the training and testing set: . vectorizer = CountVectorizer() vectorizer.fit(sentences_train) X_train = vectorizer.transform(sentences_train) X_test = vectorizer.transform(sentences_test) . X_train . &lt;750x1714 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39; with 7368 stored elements in Compressed Sparse Row format&gt; . CountVectorizer performs tokenization which separates the sentences into a set of tokens. It additionally removes punctuation and special characters and can apply other preprocessing to each word. If you want, you can use a custom tokenizer from the NLTK library with the CountVectorizer or use any number of the customizations which you can explore to improve the performance of your model. . The classification model we are going to use is the logistic regression which is a simple yet powerful linear model that is mathematically speaking in fact a form of regression between 0 and 1 based on the input feature vector. By specifying a cutoff value (by default 0.5), the regression model is used for classification. . classifier = LogisticRegression() classifier.fit(X_train, y_train) score = classifier.score(X_test, y_test) print(&quot;Accuracy:&quot;, score) . Accuracy: 0.796 . /opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . You can see that the logistic regression reached an impressive 79.6%, but let’s have a look how this model performs on the other data sets that we have. In this script, we perform and evaluate the whole process for each data set that we have: . for source in df[&#39;source&#39;].unique(): df_source = df[df[&#39;source&#39;] == source] sentences = df_source[&#39;sentence&#39;].values y = df_source[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000) vectorizer = CountVectorizer() vectorizer.fit(sentences_train) X_train = vectorizer.transform(sentences_train) X_test = vectorizer.transform(sentences_test) classifier = LogisticRegression() classifier.fit(X_train, y_train) score = classifier.score(X_test, y_test) print(&#39;Accuracy for {} data: {:.4f}&#39;.format(source, score)) . Accuracy for yelp data: 0.7960 Accuracy for amazon data: 0.7960 Accuracy for imdb data: 0.7487 . /opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . Great! You can see that this fairly simple model achieves a fairly good accuracy. . from sklearn.feature_extraction.text import TfidfTransformer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline text_clf = Pipeline([ (&#39;vect&#39;, CountVectorizer()), (&#39;clf&#39;, LogisticRegression()), ]) for source in df[&#39;source&#39;].unique(): df_source = df[df[&#39;source&#39;] == source] sentences = df_source[&#39;sentence&#39;].values y = df_source[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000) text_clf.fit(sentences_train, y_train) score = text_clf.score(sentences_test, y_test) print(&#39;Model {} Accuracy for {} data: {:.4f}&#39;.format(LogisticRegression,source, score)) . /opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for yelp data: 0.7960 Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for amazon data: 0.7960 Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for imdb data: 0.7487 . try a new feature engineering method . from sklearn.feature_extraction.text import TfidfTransformer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline text_clf = Pipeline([ (&#39;vect&#39;, CountVectorizer()), (&#39;tfidf&#39;, TfidfTransformer()), (&#39;clf&#39;, LogisticRegression()), ]) for source in df[&#39;source&#39;].unique(): df_source = df[df[&#39;source&#39;] == source] sentences = df_source[&#39;sentence&#39;].values y = df_source[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000) text_clf.fit(sentences_train, y_train) score = text_clf.score(sentences_test, y_test) print(&#39;Model {} Accuracy for {} data: {:.4f}&#39;.format(LogisticRegression,source, score)) . /opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for yelp data: 0.7680 Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for amazon data: 0.8000 Model &lt;class &#39;sklearn.linear_model.logistic.LogisticRegression&#39;&gt; Accuracy for imdb data: 0.7380 . from sklearn.feature_extraction.text import TfidfTransformer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline text_clf = Pipeline([ (&#39;vect&#39;, CountVectorizer()), (&#39;tfidf&#39;, TfidfTransformer()), (&#39;clf&#39;, MultinomialNB()), ]) for source in df[&#39;source&#39;].unique(): df_source = df[df[&#39;source&#39;] == source] sentences = df_source[&#39;sentence&#39;].values y = df_source[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000) text_clf.fit(sentences_train, y_train) score = text_clf.score(sentences_test, y_test) print(&#39;Model {} Accuracy for {} data: {:.4f}&#39;.format(MultinomialNB,source, score)) . Model &lt;class &#39;sklearn.naive_bayes.MultinomialNB&#39;&gt; Accuracy for yelp data: 0.7680 Model &lt;class &#39;sklearn.naive_bayes.MultinomialNB&#39;&gt; Accuracy for amazon data: 0.8000 Model &lt;class &#39;sklearn.naive_bayes.MultinomialNB&#39;&gt; Accuracy for imdb data: 0.7914 . Introduction to Deep Neural Networks . Neural networks, or sometimes called artificial neural network (ANN) orfeedforward neural network, are computational networks which were vaguely inspired by the neural networks in the human brain. They consist of neurons (also called nodes) which are connected like in the graph below. . You start by having a layer of input neurons where you feed in your feature vectors and the values are then feeded forward to a hidden layer. At each connection, you are feeding the value forward, while the value is multiplied by a weight and a bias is added to the value. This happens at every connection and at the end you reach an output layer with one or more output nodes. . If you want to have a binary classification you can use one node, but if you have multiple categories you should use multiple nodes for each category: . Introducing Keras . Keras is a deep learning and neural networks API by François Chollet which is capable of running on top of Tensorflow (Google), Theano or CNTK (Microsoft). To quote the wonderful book by François Chollet, Deep Learning with Python: . Keras is a model-level library, providing high-level building blocks for developing deep-learning models. It doesn’t handle low-level operations such as tensor manipulation and differentiation. Instead, it relies on a specialized, well-optimized tensor library to do so, serving as the backend engine of Keras (Source) . It is a great way to start experimenting with neural networks without having to implement every layer and piece on your own. For example Tensorflow is a great machine learning library, but you have to implement a lot of boilerplate code to have a model running. . First Keras Model . Keras supports two main types of models. You have the Sequential model API and the functional API which can do everything of the Sequential model but it can be also used for advanced models with complex network architectures. . The Sequential model is a linear stack of layers, where you can use the large variety of available layers in Keras. The most common layer is the Dense layer which is your regular densely connected neural network layer with all the weights and biases that you are already familiar with. . Before we build our model, we need to know the input dimension of our feature vectors. This happens only in the first layer since the following layers can do automatic shape inference. In order to build the Sequential model, you can add layers one by one in order . input_dim = X_train.shape[1] # Number of features model = Sequential() model.add(layers.Dense(10, input_dim=input_dim, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) . model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 10) 25060 _________________________________________________________________ dense_1 (Dense) (None, 1) 11 ================================================================= Total params: 25,071 Trainable params: 25,071 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train, epochs=100, verbose=True, validation_data=(X_test, y_test), batch_size=10) . Train on 561 samples, validate on 187 samples Epoch 1/100 561/561 [==============================] - 1s 1ms/step - loss: 0.6950 - acc: 0.5383 - val_loss: 0.7034 - val_acc: 0.5989 Epoch 2/100 561/561 [==============================] - 0s 259us/step - loss: 0.6462 - acc: 0.8128 - val_loss: 0.6702 - val_acc: 0.6631 Epoch 3/100 561/561 [==============================] - 0s 272us/step - loss: 0.5837 - acc: 0.8930 - val_loss: 0.6647 - val_acc: 0.7273 Epoch 4/100 561/561 [==============================] - 0s 281us/step - loss: 0.4959 - acc: 0.9340 - val_loss: 0.5970 - val_acc: 0.7647 Epoch 5/100 561/561 [==============================] - 0s 281us/step - loss: 0.4061 - acc: 0.9626 - val_loss: 0.5754 - val_acc: 0.7540 Epoch 6/100 561/561 [==============================] - 0s 289us/step - loss: 0.3263 - acc: 0.9715 - val_loss: 0.5543 - val_acc: 0.7647 Epoch 7/100 561/561 [==============================] - 0s 295us/step - loss: 0.2642 - acc: 0.9768 - val_loss: 0.5523 - val_acc: 0.7594 Epoch 8/100 561/561 [==============================] - 0s 284us/step - loss: 0.2162 - acc: 0.9840 - val_loss: 0.5353 - val_acc: 0.7754 Epoch 9/100 561/561 [==============================] - 0s 280us/step - loss: 0.1788 - acc: 0.9893 - val_loss: 0.5159 - val_acc: 0.7754 Epoch 10/100 561/561 [==============================] - 0s 280us/step - loss: 0.1509 - acc: 0.9911 - val_loss: 0.5228 - val_acc: 0.7968 Epoch 11/100 561/561 [==============================] - 0s 278us/step - loss: 0.1277 - acc: 0.9929 - val_loss: 0.5274 - val_acc: 0.8021 Epoch 12/100 561/561 [==============================] - 0s 307us/step - loss: 0.1098 - acc: 0.9964 - val_loss: 0.5053 - val_acc: 0.7968 Epoch 13/100 561/561 [==============================] - 0s 337us/step - loss: 0.0948 - acc: 0.9964 - val_loss: 0.5150 - val_acc: 0.7968 Epoch 14/100 561/561 [==============================] - 0s 310us/step - loss: 0.0825 - acc: 0.9982 - val_loss: 0.5304 - val_acc: 0.7968 Epoch 15/100 561/561 [==============================] - 0s 281us/step - loss: 0.0727 - acc: 0.9982 - val_loss: 0.5328 - val_acc: 0.7968 Epoch 16/100 561/561 [==============================] - 0s 301us/step - loss: 0.0643 - acc: 0.9982 - val_loss: 0.5358 - val_acc: 0.7968 Epoch 17/100 561/561 [==============================] - 0s 298us/step - loss: 0.0569 - acc: 0.9982 - val_loss: 0.5140 - val_acc: 0.7968 Epoch 18/100 561/561 [==============================] - 0s 336us/step - loss: 0.0510 - acc: 0.9982 - val_loss: 0.5344 - val_acc: 0.7968 Epoch 19/100 561/561 [==============================] - 0s 273us/step - loss: 0.0458 - acc: 0.9982 - val_loss: 0.5316 - val_acc: 0.7914 Epoch 20/100 561/561 [==============================] - 0s 272us/step - loss: 0.0413 - acc: 0.9982 - val_loss: 0.5267 - val_acc: 0.8021 Epoch 21/100 561/561 [==============================] - 0s 267us/step - loss: 0.0374 - acc: 0.9982 - val_loss: 0.5465 - val_acc: 0.8021 Epoch 22/100 561/561 [==============================] - 0s 267us/step - loss: 0.0338 - acc: 0.9982 - val_loss: 0.5581 - val_acc: 0.7914 Epoch 23/100 561/561 [==============================] - 0s 266us/step - loss: 0.0307 - acc: 0.9982 - val_loss: 0.5561 - val_acc: 0.8021 Epoch 24/100 561/561 [==============================] - 0s 266us/step - loss: 0.0280 - acc: 0.9982 - val_loss: 0.5594 - val_acc: 0.7968 Epoch 25/100 561/561 [==============================] - 0s 274us/step - loss: 0.0257 - acc: 0.9982 - val_loss: 0.5777 - val_acc: 0.7914 Epoch 26/100 561/561 [==============================] - 0s 255us/step - loss: 0.0235 - acc: 0.9982 - val_loss: 0.5786 - val_acc: 0.7968 Epoch 27/100 561/561 [==============================] - 0s 261us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.5722 - val_acc: 0.7914 Epoch 28/100 561/561 [==============================] - 0s 246us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.7914 Epoch 29/100 561/561 [==============================] - 0s 259us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.7914 Epoch 30/100 561/561 [==============================] - 0s 253us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6083 - val_acc: 0.7914 Epoch 31/100 561/561 [==============================] - 0s 275us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.7914 Epoch 32/100 561/561 [==============================] - 0s 274us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6234 - val_acc: 0.7914 Epoch 33/100 561/561 [==============================] - 0s 264us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.7861 Epoch 34/100 561/561 [==============================] - 0s 271us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.6332 - val_acc: 0.7861 Epoch 35/100 561/561 [==============================] - 0s 276us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6465 - val_acc: 0.7807 Epoch 36/100 561/561 [==============================] - 0s 266us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 0.7861 Epoch 37/100 561/561 [==============================] - 0s 270us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.6643 - val_acc: 0.7861 Epoch 38/100 561/561 [==============================] - 0s 337us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.7861 Epoch 39/100 561/561 [==============================] - 0s 306us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.7861 Epoch 40/100 561/561 [==============================] - 0s 262us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.6811 - val_acc: 0.7861 Epoch 41/100 561/561 [==============================] - 0s 272us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.6880 - val_acc: 0.7861 Epoch 42/100 561/561 [==============================] - 0s 281us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.7861 Epoch 43/100 561/561 [==============================] - 0s 273us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.6984 - val_acc: 0.7861 Epoch 44/100 561/561 [==============================] - 0s 267us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.7807 Epoch 45/100 561/561 [==============================] - 0s 277us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7098 - val_acc: 0.7861 Epoch 46/100 561/561 [==============================] - 0s 272us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7151 - val_acc: 0.7807 Epoch 47/100 561/561 [==============================] - 0s 274us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.7807 Epoch 48/100 561/561 [==============================] - 0s 266us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7257 - val_acc: 0.7807 Epoch 49/100 561/561 [==============================] - 0s 290us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.7807 Epoch 50/100 561/561 [==============================] - 0s 297us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.7807 Epoch 51/100 561/561 [==============================] - 0s 288us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.7807 Epoch 52/100 561/561 [==============================] - 0s 260us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.7464 - val_acc: 0.7807 Epoch 53/100 561/561 [==============================] - 0s 278us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.7460 - val_acc: 0.7807 Epoch 54/100 561/561 [==============================] - 0s 280us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.7807 Epoch 55/100 561/561 [==============================] - 0s 266us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.7630 - val_acc: 0.7807 Epoch 56/100 561/561 [==============================] - 0s 270us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.7807 Epoch 57/100 561/561 [==============================] - 0s 276us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.7731 - val_acc: 0.7807 Epoch 58/100 561/561 [==============================] - 0s 270us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7776 - val_acc: 0.7807 Epoch 59/100 561/561 [==============================] - 0s 270us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7818 - val_acc: 0.7807 Epoch 60/100 561/561 [==============================] - 0s 274us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7873 - val_acc: 0.7807 Epoch 61/100 561/561 [==============================] - 0s 288us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7922 - val_acc: 0.7807 Epoch 62/100 561/561 [==============================] - 0s 282us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.7965 - val_acc: 0.7807 Epoch 63/100 561/561 [==============================] - 0s 278us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.8016 - val_acc: 0.7807 Epoch 64/100 561/561 [==============================] - 0s 270us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.8052 - val_acc: 0.7807 Epoch 65/100 561/561 [==============================] - 0s 253us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.7807 Epoch 66/100 561/561 [==============================] - 0s 276us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8149 - val_acc: 0.7807 Epoch 67/100 561/561 [==============================] - 0s 276us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8196 - val_acc: 0.7807 Epoch 68/100 561/561 [==============================] - 0s 278us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8241 - val_acc: 0.7807 Epoch 69/100 561/561 [==============================] - 0s 285us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8292 - val_acc: 0.7807 Epoch 70/100 561/561 [==============================] - 0s 273us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8337 - val_acc: 0.7807 Epoch 71/100 561/561 [==============================] - 0s 280us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8377 - val_acc: 0.7807 Epoch 72/100 561/561 [==============================] - 0s 261us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8422 - val_acc: 0.7807 Epoch 73/100 561/561 [==============================] - 0s 270us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8472 - val_acc: 0.7807 Epoch 74/100 561/561 [==============================] - 0s 279us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8517 - val_acc: 0.7807 Epoch 75/100 561/561 [==============================] - 0s 249us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.7807 Epoch 76/100 561/561 [==============================] - 0s 256us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.7807 Epoch 77/100 561/561 [==============================] - 0s 264us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8653 - val_acc: 0.7807 Epoch 78/100 561/561 [==============================] - 0s 258us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.7807 Epoch 79/100 561/561 [==============================] - 0s 264us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8741 - val_acc: 0.7807 Epoch 80/100 561/561 [==============================] - 0s 267us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8750 - val_acc: 0.7807 Epoch 81/100 561/561 [==============================] - 0s 265us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8830 - val_acc: 0.7807 Epoch 82/100 561/561 [==============================] - 0s 259us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8868 - val_acc: 0.7807 Epoch 83/100 561/561 [==============================] - 0s 274us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8915 - val_acc: 0.7807 Epoch 84/100 561/561 [==============================] - 0s 266us/step - loss: 9.9007e-04 - acc: 1.0000 - val_loss: 0.8952 - val_acc: 0.7807 Epoch 85/100 561/561 [==============================] - 0s 268us/step - loss: 9.5113e-04 - acc: 1.0000 - val_loss: 0.9001 - val_acc: 0.7807 Epoch 86/100 561/561 [==============================] - 0s 260us/step - loss: 9.1544e-04 - acc: 1.0000 - val_loss: 0.9043 - val_acc: 0.7807 Epoch 87/100 561/561 [==============================] - 0s 274us/step - loss: 8.7950e-04 - acc: 1.0000 - val_loss: 0.9091 - val_acc: 0.7807 Epoch 88/100 561/561 [==============================] - 0s 269us/step - loss: 8.4632e-04 - acc: 1.0000 - val_loss: 0.9140 - val_acc: 0.7807 Epoch 89/100 561/561 [==============================] - 0s 261us/step - loss: 8.1522e-04 - acc: 1.0000 - val_loss: 0.9175 - val_acc: 0.7807 Epoch 90/100 561/561 [==============================] - 0s 274us/step - loss: 7.8102e-04 - acc: 1.0000 - val_loss: 0.9215 - val_acc: 0.7807 Epoch 91/100 561/561 [==============================] - 0s 276us/step - loss: 7.5320e-04 - acc: 1.0000 - val_loss: 0.9260 - val_acc: 0.7807 Epoch 92/100 561/561 [==============================] - 0s 267us/step - loss: 7.2292e-04 - acc: 1.0000 - val_loss: 0.9307 - val_acc: 0.7807 Epoch 93/100 561/561 [==============================] - 0s 271us/step - loss: 6.9741e-04 - acc: 1.0000 - val_loss: 0.9349 - val_acc: 0.7807 Epoch 94/100 561/561 [==============================] - 0s 269us/step - loss: 6.7042e-04 - acc: 1.0000 - val_loss: 0.9382 - val_acc: 0.7807 Epoch 95/100 561/561 [==============================] - 0s 267us/step - loss: 6.4420e-04 - acc: 1.0000 - val_loss: 0.9433 - val_acc: 0.7807 Epoch 96/100 561/561 [==============================] - 0s 251us/step - loss: 6.2090e-04 - acc: 1.0000 - val_loss: 0.9476 - val_acc: 0.7807 Epoch 97/100 561/561 [==============================] - 0s 264us/step - loss: 5.9885e-04 - acc: 1.0000 - val_loss: 0.9520 - val_acc: 0.7807 Epoch 98/100 561/561 [==============================] - 0s 251us/step - loss: 5.7492e-04 - acc: 1.0000 - val_loss: 0.9559 - val_acc: 0.7807 Epoch 99/100 561/561 [==============================] - 0s 266us/step - loss: 5.5424e-04 - acc: 1.0000 - val_loss: 0.9601 - val_acc: 0.7807 Epoch 100/100 561/561 [==============================] - 0s 266us/step - loss: 5.3424e-04 - acc: 1.0000 - val_loss: 0.9638 - val_acc: 0.7807 . loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) . Training Accuracy: 1.0000 Testing Accuracy: 0.7807 . def plot_history(history): acc = history.history[&#39;acc&#39;] val_acc = history.history[&#39;val_acc&#39;] loss = history.history[&#39;loss&#39;] val_loss = history.history[&#39;val_loss&#39;] x = range(1, len(acc) + 1) plt.figure(figsize=(12, 5)) plt.subplot(1, 2, 1) plt.plot(x, acc, &#39;b&#39;, label=&#39;Training acc&#39;) plt.plot(x, val_acc, &#39;r&#39;, label=&#39;Validation acc&#39;) plt.title(&#39;Training and validation accuracy&#39;) plt.legend() plt.subplot(1, 2, 2) plt.plot(x, loss, &#39;b&#39;, label=&#39;Training loss&#39;) plt.plot(x, val_loss, &#39;r&#39;, label=&#39;Validation loss&#39;) plt.title(&#39;Training and validation loss&#39;) plt.legend() . plot_history(history) . What Is a Word Embedding? . Text is considered a form of sequence data similar to time series data that you would have in weather data or financial data. Now you will see how to represent each word as vectors. There are various ways to vectorize text, such as: . Words represented by each word as a vector | Characters represented by each character as a vector | N-grams of words/characters represented as a vector (N-grams are overlapping groups of multiple succeeding words/characters in the text) | . Here, you’ll see how to deal with representing words as vectors which is the common way to use text in neural networks. Two possible ways to represent a word as a vector are one-hot encoding and word embeddings. . One-Hot Encoding . The first way to represent a word as a vector is by creating a so-called one-hot encoding, which is simply done by taking a vector of the length of the vocabulary with an entry for each word in the corpus. . In this way, you have for each word, given it has a spot in the vocabulary, a vector with zeros everywhere except for the corresponding spot for the word which is set to one. . cities = [&#39;London&#39;, &#39;Berlin&#39;, &#39;Berlin&#39;, &#39;New York&#39;, &#39;London&#39;] cities . [&#39;London&#39;, &#39;Berlin&#39;, &#39;Berlin&#39;, &#39;New York&#39;, &#39;London&#39;] . LabelEncoder to encode the list of cities into categorical integer values . encoder = LabelEncoder() city_labels = encoder.fit_transform(cities) city_labels . array([1, 0, 0, 2, 1]) . OneHotEncoder expects each categorical value to be in a separate row, so you’ll need to reshape the array, then you can apply the encoder: . encoder = OneHotEncoder(sparse=False) city_labels = city_labels.reshape((5, 1)) encoder.fit_transform(city_labels) . /opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values. If you want the future behaviour and silence this warning, you can specify &#34;categories=&#39;auto&#39;&#34;. In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly. warnings.warn(msg, FutureWarning) . array([[0., 1., 0.], [1., 0., 0.], [1., 0., 0.], [0., 0., 1.], [0., 1., 0.]]) . Word Embeddings . This method represents words as dense word vectors (also called word embeddings) which are trained unlike the one-hot encoding which are hardcoded. This means that the word embeddings collect more information into fewer dimensions. . Note that the word embeddings do not understand the text as a human would, but they rather map the statistical structure of the language used in the corpus. Their aim is to map semantic meaning into a geometric space. This geometric space is then called the embedding space. . Now you need to tokenize the data into a format that can be used by the word embeddings. Keras offers a couple of convenience methods for text preprocessing and sequence preprocessing which you can employ to prepare your text. . You can start by using the Tokenizer utility class which can vectorize a text corpus into a list of integers. Each integer maps to a value in a dictionary that encodes the entire corpus, with the keys in the dictionary being the vocabulary terms themselves. You can add the parameter num_words, which is responsible for setting the size of the vocabulary. The most common num_words words will be then kept. . tokenizer = Tokenizer(num_words=5000) tokenizer.fit_on_texts(sentences_train) X_train = tokenizer.texts_to_sequences(sentences_train) X_test = tokenizer.texts_to_sequences(sentences_test) vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index print(sentences_train[2]) print(X_train[2]) . I am a fan of his ... This movie sucked really bad. [7, 150, 2, 932, 4, 49, 6, 11, 563, 45, 30] . for word in [&#39;the&#39;, &#39;all&#39;,&#39;fan&#39;]: print(&#39;{}: {}&#39;.format(word, tokenizer.word_index[word])) . the: 1 all: 27 fan: 932 . pad sequences with Keras . maxlen = 100 X_train = pad_sequences(X_train, padding=&#39;post&#39;, maxlen=maxlen) X_test = pad_sequences(X_test, padding=&#39;post&#39;, maxlen=maxlen) print(X_train[0, :]) . [170 116 390 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . Keras Embedding Layer . Now you can use the Embedding Layer of Keras which takes the previously calculated integers and maps them to a dense vector of the embedding. You will need the following parameters: . input_dim: the size of the vocabulary | output_dim: the size of the dense vector | input_length: the length of the sequence | . With the Embedding layer we have now a couple of options. One way would be to take the output of the embedding layer and plug it into a Dense layer. In order to do this you have to add a Flatten layer in between that prepares the sequential input for the Dense layer: . embedding_dim = 50 model = Sequential() model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen)) model.add(layers.Flatten()) model.add(layers.Dense(10, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 100, 50) 128750 _________________________________________________________________ flatten (Flatten) (None, 5000) 0 _________________________________________________________________ dense_2 (Dense) (None, 10) 50010 _________________________________________________________________ dense_3 (Dense) (None, 1) 11 ================================================================= Total params: 178,771 Trainable params: 178,771 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train, epochs=20, verbose=True, validation_data=(X_test, y_test), batch_size=10) loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) plot_history(history) . /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; . Train on 561 samples, validate on 187 samples Epoch 1/20 561/561 [==============================] - 1s 1ms/step - loss: 0.6983 - acc: 0.4742 - val_loss: 0.6931 - val_acc: 0.4920 Epoch 2/20 561/561 [==============================] - 0s 459us/step - loss: 0.6869 - acc: 0.5383 - val_loss: 0.6940 - val_acc: 0.4920 Epoch 3/20 561/561 [==============================] - 0s 456us/step - loss: 0.6600 - acc: 0.5348 - val_loss: 0.7007 - val_acc: 0.4920 Epoch 4/20 561/561 [==============================] - 0s 460us/step - loss: 0.5818 - acc: 0.6221 - val_loss: 0.6902 - val_acc: 0.5134 Epoch 5/20 561/561 [==============================] - 0s 473us/step - loss: 0.3579 - acc: 0.9376 - val_loss: 0.6579 - val_acc: 0.6150 Epoch 6/20 561/561 [==============================] - 0s 472us/step - loss: 0.1302 - acc: 0.9911 - val_loss: 0.6513 - val_acc: 0.6150 Epoch 7/20 561/561 [==============================] - 0s 461us/step - loss: 0.0522 - acc: 0.9982 - val_loss: 0.6917 - val_acc: 0.5882 Epoch 8/20 561/561 [==============================] - 0s 465us/step - loss: 0.0298 - acc: 0.9964 - val_loss: 0.6838 - val_acc: 0.6257 Epoch 9/20 561/561 [==============================] - 0s 474us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.7416 - val_acc: 0.6417 Epoch 10/20 561/561 [==============================] - 0s 481us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.6257 Epoch 11/20 561/561 [==============================] - 0s 474us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.6471 Epoch 12/20 561/561 [==============================] - 0s 471us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.6631 Epoch 13/20 561/561 [==============================] - 0s 451us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7697 - val_acc: 0.6578 Epoch 14/20 561/561 [==============================] - 0s 455us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.7777 - val_acc: 0.6310 Epoch 15/20 561/561 [==============================] - 0s 452us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7800 - val_acc: 0.6471 Epoch 16/20 561/561 [==============================] - 0s 434us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.8033 - val_acc: 0.6524 Epoch 17/20 561/561 [==============================] - 0s 450us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8045 - val_acc: 0.6417 Epoch 18/20 561/561 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8138 - val_acc: 0.6417 Epoch 19/20 561/561 [==============================] - 0s 454us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.6417 Epoch 20/20 561/561 [==============================] - 0s 464us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8331 - val_acc: 0.6524 Training Accuracy: 1.0000 Testing Accuracy: 0.6524 . Global max/average pooling takes the maximum/average of all features whereas in the other case you have to define the pool size. Keras has again its own layer that you can add in the sequential model: . embedding_dim = 50 model = Sequential() model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen)) model.add(layers.GlobalMaxPool1D()) model.add(layers.Dense(10, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, 100, 50) 128750 _________________________________________________________________ global_max_pooling1d (Global (None, 50) 0 _________________________________________________________________ dense_4 (Dense) (None, 10) 510 _________________________________________________________________ dense_5 (Dense) (None, 1) 11 ================================================================= Total params: 129,271 Trainable params: 129,271 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train, epochs=50, verbose=False, validation_data=(X_test, y_test), batch_size=10) loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) plot_history(history) . /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; . Training Accuracy: 1.0000 Testing Accuracy: 0.7914 . Convolutional Neural Networks (CNN) . Convolutional neural networks or also called convnets are one of the most exciting developments in machine learning in recent years. . They have revolutionized image classification and computer vision by being able to extract features from images and using them in neural networks. The properties that made them useful in image processing makes them also handy for sequence processing. You can imagine a CNN as a specialized neural network that is able to detect specific patterns. . A CNN has hidden layers which are called convolutional layers. When you think of images, a computer has to deal with a two dimensional matrix of numbers and therefore you need some way to detect features in this matrix. These convolutional layers are able to detect edges, corners and other kinds of textures which makes them such a special tool. The convolutional layer consists of multiple filters which are slid across the image and are able to detect specific features. . embedding_dim = 100 model = Sequential() model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)) model.add(layers.Conv1D(128, 5, activation=&#39;relu&#39;)) model.add(layers.GlobalMaxPooling1D()) model.add(layers.Dense(10, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_2 (Embedding) (None, 100, 100) 257500 _________________________________________________________________ conv1d (Conv1D) (None, 96, 128) 64128 _________________________________________________________________ global_max_pooling1d_1 (Glob (None, 128) 0 _________________________________________________________________ dense_6 (Dense) (None, 10) 1290 _________________________________________________________________ dense_7 (Dense) (None, 1) 11 ================================================================= Total params: 322,929 Trainable params: 322,929 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train, epochs=10, verbose=False, validation_data=(X_test, y_test), batch_size=10) loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) plot_history(history) . /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; . Training Accuracy: 1.0000 Testing Accuracy: 0.7914 . Hyperparameters Optimization . One crucial steps of deep learning and working with neural networks is hyperparameter optimization. . As you saw in the models that we have used so far, even with simpler ones, you had a large number of parameters to tweak and choose from. Those parameters are called hyperparameters. This is the most time consuming part of machine learning and sadly there are no one-fits-all solutions ready. . One popular method for hyperparameter optimization is grid search. What this method does is it takes lists of parameters and it runs the model with each parameter combination that it can find. It is the most thorough way but also the most computationally heavy way to do this. Another common way,random search, which you’ll see in action here, simply takes random combinations of parameters. . In order to apply random search with Keras, you will need to use the KerasClassifier which serves as a wrapper for the scikit-learn API. With this wrapper you are able to use the various tools available with scikit-learn like cross-validation. The class that you need is RandomizedSearchCV which implements random search with cross-validation. Cross-validation is a way to validate the model and take the whole data set and separate it into multiple testing and training data sets. . There are various types of cross-validation. One type is the k-fold cross-validation. In this type the data set is partitioned into k equal sized sets where one set is used for testing and the rest of the partitions are used for training. This enables you to run k different runs, where each partition is once used as a testing set. So, the higher k is the more accurate the model evaluation is, but the smaller each testing set is. . def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen): model = Sequential() model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)) model.add(layers.Conv1D(num_filters, kernel_size, activation=&#39;relu&#39;)) model.add(layers.GlobalMaxPooling1D()) model.add(layers.Dense(10, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) return model . param_grid = dict(num_filters=[32, 64, 128], kernel_size=[3, 5, 7], vocab_size=[5000], embedding_dim=[50], maxlen=[100]) . epochs = 20 embedding_dim = 50 maxlen = 100 output_file = &#39;output.txt&#39; # Run grid search for each source (yelp, amazon, imdb) for source, frame in df.groupby(&#39;source&#39;): print(&#39;Running grid search for data set :&#39;, source) sentences = df[&#39;sentence&#39;].values y = df[&#39;label&#39;].values # Train-test split sentences_train, sentences_test, y_train, y_test = train_test_split( sentences, y, test_size=0.25, random_state=1000) # Tokenize words tokenizer = Tokenizer(num_words=5000) tokenizer.fit_on_texts(sentences_train) X_train = tokenizer.texts_to_sequences(sentences_train) X_test = tokenizer.texts_to_sequences(sentences_test) # Adding 1 because of reserved 0 index vocab_size = len(tokenizer.word_index) + 1 # Pad sequences with zeros X_train = pad_sequences(X_train, padding=&#39;post&#39;, maxlen=maxlen) X_test = pad_sequences(X_test, padding=&#39;post&#39;, maxlen=maxlen) # Parameter grid for grid search param_grid = dict(num_filters=[32, 64, 128], kernel_size=[3, 5, 7], vocab_size=[vocab_size], embedding_dim=[embedding_dim], maxlen=[maxlen]) model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=10, verbose=False) grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=4, verbose=1, n_iter=5) grid_result = grid.fit(X_train, y_train) # Evaluate testing set test_accuracy = grid.score(X_test, y_test) # Save and evaluate results # prompt = input(f&#39;finished {source}; write to file and proceed? [y/n]&#39;) # if prompt.lower() not in {&#39;y&#39;, &#39;true&#39;, &#39;yes&#39;}: # break # with open(output_file, &#39;w+&#39;) as f: s = (&#39;Running {} data set nBest Accuracy : &#39; &#39;{:.4f} n{} nTest Accuracy : {:.4f} n n&#39;) output_string = s.format( source, grid_result.best_score_, grid_result.best_params_, test_accuracy) print(output_string) # f.write(output_string) . Running grid search for data set : amazon Fitting 4 folds for each of 5 candidates, totalling 20 fits . [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; [Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 11.6min finished . Running amazon data set Best Accuracy : 0.8205 {&#39;vocab_size&#39;: 4603, &#39;num_filters&#39;: 64, &#39;maxlen&#39;: 100, &#39;kernel_size&#39;: 3, &#39;embedding_dim&#39;: 50} Test Accuracy : 0.8268 Running grid search for data set : imdb Fitting 4 folds for each of 5 candidates, totalling 20 fits . [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. [Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 13.8min finished . Running imdb data set Best Accuracy : 0.8190 {&#39;vocab_size&#39;: 4603, &#39;num_filters&#39;: 128, &#39;maxlen&#39;: 100, &#39;kernel_size&#39;: 3, &#39;embedding_dim&#39;: 50} Test Accuracy : 0.8180 Running grid search for data set : yelp Fitting 4 folds for each of 5 candidates, totalling 20 fits . [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. [Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 15.6min finished . Running yelp data set Best Accuracy : 0.8127 {&#39;vocab_size&#39;: 4603, &#39;num_filters&#39;: 64, &#39;maxlen&#39;: 100, &#39;kernel_size&#39;: 5, &#39;embedding_dim&#39;: 50} Test Accuracy : 0.8282 .",
            "url": "https://taocao.github.io/ml/2022/05/31/Extracting-features-from-text-files.html",
            "relUrl": "/2022/05/31/Extracting-features-from-text-files.html",
            "date": " • May 31, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . df = pd.read_json(movies) # load movies data df.columns = [x.replace(&#39; &#39;, &#39;_&#39;) for x in df.columns.values] genres = df[&#39;Major_Genre&#39;].unique() # get unique field values genres = list(filter(lambda d: d is not None, genres)) # filter out None values genres.sort() # sort alphabetically . . mpaa = [&#39;G&#39;, &#39;PG&#39;, &#39;PG-13&#39;, &#39;R&#39;, &#39;NC-17&#39;, &#39;Not Rated&#39;] . . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_284x96dp.png) . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . curricula in engineering scienc have little exposure to data methods or optimization. computer scientists and statisticians have little exposure to dynamical systems and control. Our goal is to provide entry point to applied data science for both of these groups of students. https://t.co/ozbDG9ay2l . &mdash; Tao Cao (@taocds) May 28, 2022 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://taocao.github.io/ml/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://taocao.github.io/ml/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://taocao.github.io/ml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://taocao.github.io/ml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}